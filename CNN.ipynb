{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEtR8P8MGhSX"
   },
   "source": [
    "# Processing for local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5S5KWJQSHn3z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#!tar -xf data/for-rerec.tar.gz -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xbEPVigKihN",
    "outputId": "2aefed60-6275-444c-f190-753329d620b2"
   },
   "outputs": [],
   "source": [
    "#ls data/for-rerecorded/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSWk1DLnIi_O",
    "outputId": "7747b4d1-d172-4189-d0fd-bc70149bf201"
   },
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision librosa matplotlib tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8omdaYcFI6hU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUWaXDsKNQ31"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7wm4V3FxPjGC"
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000  # Sampling rate\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5DdJBRQqNS9C"
   },
   "outputs": [],
   "source": [
    "# TODO: Make it so each output is \"513-dimensional\" as with the reference paper\n",
    "#\n",
    "# https://arxiv.org/pdf/2203.16263\n",
    "\n",
    "def compute_spectrograms(path):\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    fixed_length = 2 * SAMPLE_RATE\n",
    "    if len(y) < fixed_length:\n",
    "        y = np.pad(y, (0, fixed_length - len(y)))\n",
    "    else:\n",
    "        y = y[:fixed_length]\n",
    "\n",
    "    cqt = librosa.cqt(y, sr=sr)\n",
    "    cqt_spec = librosa.amplitude_to_db(np.abs(cqt), ref=np.max)\n",
    "\n",
    "    stft = librosa.stft(y)\n",
    "    log_spec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "    mel_spec = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    return cqt_spec, log_spec, mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = {\n",
    "    'training_fake': 'data/for-rerecorded/training/fake/',\n",
    "    'testing_fake': 'data/for-rerecorded/testing/fake/',\n",
    "    'validation_fake': 'data/for-rerecorded/validation/fake/',\n",
    "    'training_real': 'data/for-rerecorded/training/real/',\n",
    "    'testing_real': 'data/for-rerecorded/testing/real/',\n",
    "    'validation_real': 'data/for-rerecorded/validation/real/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6PzYHa5TqHT",
    "outputId": "c364cca2-105e-4aab-9763-0f2e211e8443"
   },
   "outputs": [],
   "source": [
    "def process_directory(directory, output_dir):\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.wav'):\n",
    "      audio_path = os.path.join(directory, filename)\n",
    "      cqt, log, mel = compute_spectrograms(audio_path)\n",
    "\n",
    "      base_name = os.path.splitext(filename)[0]\n",
    "      # Save spectrograms as numpy arrays\n",
    "      np.save(f\"{output_dir}/{base_name}_cqt.npy\", cqt)\n",
    "      np.save(f\"{output_dir}/{base_name}_log.npy\", log)\n",
    "      np.save(f\"{output_dir}/{base_name}_mel.npy\", mel)\n",
    "\n",
    "compute_specs = False\n",
    "if compute_specs:\n",
    "    for set_name, directory in data_dirs.items():\n",
    "      output_dir = f'data/spectrograms/{set_name}_spectrograms'\n",
    "      process_directory(directory, output_dir)\n",
    "      print(f\"Processed {set_name} set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 86)\n",
      "(1025, 86)\n",
      "(128, 86)\n"
     ]
    }
   ],
   "source": [
    "# lets look at some data\n",
    "display_cqt = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_cqt.npy\"\n",
    "display_log = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_log.npy\"\n",
    "display_mel = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_mel.npy\"\n",
    "\n",
    "cqt_test = np.load(display_cqt)\n",
    "log_test = np.load(display_log)\n",
    "mel_test = np.load(display_mel)\n",
    "print(cqt_test.shape)\n",
    "print(log_test.shape)\n",
    "print(mel_test.shape)\n",
    "\n",
    "# for reference\n",
    "cqt_size = 84\n",
    "log_size = 1025\n",
    "mel_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-DJw8fFNZXj"
   },
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S2eATQYGNaUY"
   },
   "outputs": [],
   "source": [
    "class ResNet50Spectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50Spectrogram, self).__init__()\n",
    "\n",
    "        self.model = models.resnet50(weights=None)\n",
    "\n",
    "        original_conv = self.model.conv1\n",
    "        self.model.conv1 = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetSpectrogram(nn.Module):\n",
    "    def __init__(self, model_type):\n",
    "        super(EfficientNetSpectrogram, self).__init__()\n",
    "        \n",
    "        self.enet = None\n",
    "        \n",
    "        if model_type == \"b0\":\n",
    "            self.enet = models.efficientnet_b0(weights=None, num_classes=2)\n",
    "            \n",
    "        \n",
    "        # We need to change the network to accept 1 channel instead of\n",
    "        # 3 because of our data.\n",
    "        original_conv = self.enet.features[0][0]\n",
    "        new_conv = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "        self.enet.features[0][0] = new_conv\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.enet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSpectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMSpectrogram, self).__init__()\n",
    "        \n",
    "        self.nlayer = 2\n",
    "        self.nhiddens = 256\n",
    "        \n",
    "        if feature_type == \"cqt\":\n",
    "            self.lstm = nn.LSTM(input_size=cqt_size, hidden_size=self.nhiddens, num_layers=self.nlayer, \n",
    "                                batch_first=True, dropout=0.3)\n",
    "        elif feature_type == \"log\":\n",
    "            self.lstm = nn.LSTM(input_size=log_size, hidden_size=self.nhiddens, num_layers=self.nlayer, \n",
    "                                batch_first=True, dropout=0.3)\n",
    "        elif feature_type == \"mel\":\n",
    "            self.lstm = nn.LSTM(input_size=mel_size, hidden_size=self.nhiddens, num_layers=self.nlayer, \n",
    "                                batch_first=True, dropout=0.3)\n",
    "            \n",
    "        self.fc = nn.Linear(self.nhiddens, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        # features are in wrong order for lstm\n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "        x, (h_o, c_o) = self.lstm(x)\n",
    "        \n",
    "        h_o = h_o.squeeze(0)\n",
    "        if self.nlayer > 1:\n",
    "            h_o = h_o[-1]\n",
    "        x = self.fc(h_o)\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "        #x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecDataset(Dataset):\n",
    "    # data_type is one of 'cqt', 'log', 'mel'\n",
    "    #\n",
    "    # loader_type is one of 'train', 'validation', 'test'\n",
    "    def __init__(self, data_type, loader_type):\n",
    "        \n",
    "        root = os.getcwd()\n",
    "        data_root = os.path.join(root, 'data/spectrograms')\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        real_folder = None\n",
    "        fake_folder = None\n",
    "\n",
    "        # get the folder\n",
    "        if loader_type == \"train\":\n",
    "            real_folder = os.path.join(data_root, 'training_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'training_fake_spectrograms')\n",
    "        elif loader_type == \"validation\":\n",
    "            real_folder = os.path.join(data_root, 'validation_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'validation_fake_spectrograms')\n",
    "        elif loader_type == \"test\":\n",
    "            real_folder = os.path.join(data_root, 'testing_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'testing_fake_spectrograms')\n",
    "        elif loader_type == \"ITWtest\":\n",
    "            real_folder = os.path.join(data_root, 'ITWtest_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'ITWtest_fake_spectrograms')\n",
    "        else:\n",
    "            # Should never occur.\n",
    "            pass\n",
    "        \n",
    "        real_files = []\n",
    "        fake_files = []\n",
    "        \n",
    "        # now we have the folder given the loader type, collect\n",
    "        # the data required for the loader.\n",
    "        \n",
    "        # get real example filenames\n",
    "        suffix = f\"{data_type}.npy\"\n",
    "        for filename in os.listdir(real_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(real_folder, filename)):\n",
    "                this_filepath = os.path.join(real_folder, filename)\n",
    "                real_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Real examples for {data_type} {loader_type}: {len(real_files)}\")\n",
    "        \n",
    "        # get fake example filenames\n",
    "        suffix = f\"{data_type}.npy\"\n",
    "        for filename in os.listdir(fake_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(fake_folder, filename)):\n",
    "                this_filepath = os.path.join(fake_folder, filename)\n",
    "                fake_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Fake examples for {data_type} {loader_type}: {len(fake_files)}\")\n",
    "        \n",
    "        label_val_false = 0\n",
    "        label_val_true = 1\n",
    "        if model_type == \"LSTM\":\n",
    "            label_val_false = float(0)\n",
    "            label_val_true = float(1)\n",
    "        \n",
    "        # load the data into memory\n",
    "        #\n",
    "        # if we need to work with a larger dataset, you might need to\n",
    "        # alter this to be lazy loading instead, but it fits in my main memory\n",
    "        # because of how much I currently have.\n",
    "        for real_file in real_files:\n",
    "            rf_data = torch.tensor(np.load(real_file))\n",
    "            rf_data = rf_data.unsqueeze(0)\n",
    "            if resizing == True:\n",
    "                rf_data = rf_data.unsqueeze(0)\n",
    "                rf_data = F.interpolate(rf_data, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "                rf_data = rf_data.squeeze(0)\n",
    "            self.data.append((rf_data,label_val_true))\n",
    "            \n",
    "        for fake_file in fake_files:\n",
    "            ff_data = torch.tensor(np.load(fake_file))\n",
    "            ff_data = ff_data.unsqueeze(0)\n",
    "            if resizing == True:\n",
    "                ff_data = ff_data.unsqueeze(0)\n",
    "                ff_data = F.interpolate(ff_data, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "                ff_data = ff_data.squeeze(0)\n",
    "            self.data.append((ff_data, label_val_false))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # return the data and the label\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_collate(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    data = [d for d in data]\n",
    "    \n",
    "    max_length = max(d.shape[2] for d in data)\n",
    "    \n",
    "    padded = []\n",
    "    if resizing == False:\n",
    "        for d in data:\n",
    "            # total padding needed, >= 0\n",
    "            padding = max_length - d.shape[2]\n",
    "        \n",
    "            padded_d = None\n",
    "            if padding > 0:\n",
    "                # add zero's (silence) to match rest of batch\n",
    "                padded_data = F.pad(d, (0,padding))\n",
    "            \n",
    "            else:\n",
    "                # already max length\n",
    "                padded_data = d\n",
    "            padded.append(padded_data)\n",
    "    else:\n",
    "        # if resizing was true, we don't need to pad, everything is of the same shape\n",
    "        padded = data\n",
    "    \n",
    "    '''\n",
    "    for p in padded:\n",
    "        r = p.unsqueeze(0)\n",
    "        r = F.interpolate(r, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "        r = r.squeeze(0)\n",
    "        resized.append(r)\n",
    "    '''\n",
    "    \n",
    "    # stack properly now that everything is padded\n",
    "    padded = torch.stack(padded, dim=0)\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return padded, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real examples for cqt train: 5104\n",
      "Fake examples for cqt train: 5104\n",
      "Real examples for cqt validation: 1101\n",
      "Fake examples for cqt validation: 1143\n",
      "Real examples for cqt test: 408\n",
      "Fake examples for cqt test: 408\n"
     ]
    }
   ],
   "source": [
    "#mean = [0]\n",
    "#std = [1]\n",
    "\n",
    "# deal with this later\n",
    "#\n",
    "# we should also probably compute the mean and std manually instead of assuming they correctly\n",
    "# normalized it, since this is the re-recorded dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(mean, std)\n",
    "  ])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "####################################################\n",
    "# <CHANGE ME> if you want to use different features!\n",
    "####################################################\n",
    "feature_type = \"cqt\"\n",
    "\n",
    "####################################################\n",
    "# <CHANGE ME> if you want to use resizing!\n",
    "#\n",
    "# We need to resize to, for example, (224, 224)\n",
    "####################################################\n",
    "resizing = False\n",
    "dims_resize = (224, 224)\n",
    "\n",
    "#model_type = \"enet\"\n",
    "model_type = \"res\"\n",
    "#model_type = \"LSTM\"\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = None\n",
    "\n",
    "if model_type == \"LSTM\":\n",
    "    model = LSTMSpectrogram()\n",
    "elif model_type == \"enet\":\n",
    "    model =  EfficientNetSpectrogram(\"b0\")\n",
    "elif model_type == \"res\":\n",
    "    model = ResNet50Spectrogram()\n",
    "    \n",
    "model = model.to(device)\n",
    "\n",
    "#epochs = 100\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "weight_decay = 5e-4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if model_type == \"LSTM\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "\n",
    "FoR_train_loader = None\n",
    "FoR_val_loader = None\n",
    "FoR_test_loader = None\n",
    "\n",
    "# data loaders\n",
    "FoR_train_dataset = SpecDataset(feature_type, \"train\")\n",
    "FoR_val_dataset = SpecDataset(feature_type, \"validation\")\n",
    "FoR_test_dataset = SpecDataset(feature_type, \"test\")\n",
    "\n",
    "FoR_train_loader = DataLoader(FoR_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "FoR_val_loader = DataLoader(FoR_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "FoR_test_loader = DataLoader(FoR_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to compute the equal error rate as one of our metrics.\n",
    "def compute_EER(model, loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            waveform, labels = data\n",
    "            \n",
    "            waveform = waveform.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            out = model(waveform)\n",
    "            if model_type == \"LSTM\":\n",
    "                out = torch.sigmoid(out)\n",
    "            else:\n",
    "                out = torch.softmax(out, dim=1)\n",
    "                # take the positive class labels\n",
    "                out = out[:,1]\n",
    "            \n",
    "            all_scores.extend(out.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # use sklearn to compute this for us\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "    \n",
    "    # definition\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # find closest threshold\n",
    "    eer_thresh = np.nanargmin(np.abs(fpr-fnr))\n",
    "    EER = (fpr[eer_thresh] + fnr[eer_thresh])/2\n",
    "    \n",
    "    return EER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    \n",
    "    for data in loader:\n",
    "        waveform, labels = data\n",
    "        waveform = waveform.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # basic pytorch boilerplate\n",
    "        out = model(waveform)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    training_loss = training_loss / len(loader)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader):\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            waveform, labels = data\n",
    "            \n",
    "            waveform = waveform.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            out = model(waveform)\n",
    "            loss = criterion(out, labels)\n",
    "            \n",
    "            validation_loss += loss.item()\n",
    "            \n",
    "            # count correct predictions\n",
    "            preds = None\n",
    "            if model_type == \"LSTM\":\n",
    "                preds = (out > 0).long()\n",
    "            else:\n",
    "                preds = out.argmax(dim=1)\n",
    "            \n",
    "            n_correct = n_correct + (preds == labels).sum().item()\n",
    "            n_total = n_total + labels.size(0)\n",
    "            \n",
    "    validation_loss = validation_loss / len(loader)\n",
    "    accuracy = n_correct / n_total\n",
    "    \n",
    "    return validation_loss, accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/30 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m test_losses = []\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     training_loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFoR_train_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     training_losses.append(training_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(loader)\u001b[39m\n\u001b[32m     15\u001b[39m     loss.backward()\n\u001b[32m     16\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     training_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m training_loss = training_loss / \u001b[38;5;28mlen\u001b[39m(loader)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m training_loss\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# reference paper uses patience = 5\n",
    "patience = 5\n",
    "best_validation_loss = 10000.0\n",
    "fail_count = 0\n",
    "\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    training_loss = train(FoR_train_loader)\n",
    "    print(f\"[Epoch {epoch}] Training Loss: {training_loss}\")\n",
    "    \n",
    "    training_losses.append(training_loss)\n",
    "    \n",
    "    validation_loss, val_accuracy = validate(FoR_val_loader)    \n",
    "    print(f\"[Epoch {epoch}] Validation Loss: {validation_loss} Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    val_losses.append(validation_loss)\n",
    "    \n",
    "    test_loss, test_accuracy = validate(FoR_test_loader)\n",
    "    print(f\"[DEBUG Epoch {epoch}] Test Loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        fail_count = 0\n",
    "    else:\n",
    "        # increment number of epochs of no improvement\n",
    "        fail_count = fail_count + 1\n",
    "        \n",
    "    if fail_count >= patience:\n",
    "        print(f\"Triggering early breaking on epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test EER: {compute_EER(model, FoR_test_loader)}\")\n",
    "test_loss, test_accuracy = validate(FoR_test_loader)\n",
    "print(f\"Testing loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "\n",
    "# expected to be quite low, though obvious overfitting at current settings\n",
    "print(f\"Train EER: {compute_EER(model, FoR_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(training_losses)), training_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\", marker='s')\n",
    "plt.plot(range(len(test_losses)), test_losses, label=\"Test Loss\", marker='x')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ITW Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('data/release_in_the_wild.zip') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_csv = 'data/release_in_the_wild/meta.csv'\n",
    "\n",
    "df = pd.read_csv(src_csv)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = row['file']\n",
    "    label = str(row['label'])\n",
    "\n",
    "    src_path = os.path.join('data/release_in_the_wild', name)\n",
    "    dst_dir = os.path.join('data/release_in_the_wild', label)\n",
    "    dst_path = os.path.join(dst_dir, name)\n",
    "\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "os.rename('data/release_in_the_wild/bona-fide', 'data/release_in_the_wild/real')\n",
    "os.rename('data/release_in_the_wild/spoof', 'data/release_in_the_wild/fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory, output_dir):\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith('.wav'):\n",
    "      audio_path = os.path.join(directory, filename)\n",
    "      cqt, log, mel = compute_spectrograms(audio_path)\n",
    "\n",
    "      base_name = os.path.splitext(filename)[0]\n",
    "      # Save spectrograms as numpy arrays\n",
    "      np.save(f\"{output_dir}/{base_name}_cqt.npy\", cqt)\n",
    "      np.save(f\"{output_dir}/{base_name}_log.npy\", log)\n",
    "      np.save(f\"{output_dir}/{base_name}_mel.npy\", mel)\n",
    "\n",
    "data_dirs = {\n",
    "    'ITWtest_real': 'data/release_in_the_wild/real',\n",
    "    'ITWtest_fake': 'data/release_in_the_wild/fake/'\n",
    "}\n",
    "\n",
    "for set_name, directory in data_dirs.items():\n",
    "    output_dir = f'data/spectrograms/{set_name}_spectrograms'\n",
    "    process_directory(directory, output_dir)\n",
    "    print(f\"Processed {set_name} set.\")\n",
    "\n",
    "feature_type = \"cqt\"\n",
    "batch_size = 128\n",
    "resizing = True\n",
    "dims_resize = (224, 224)\n",
    "\n",
    "ITW_test_dataset = SpecDataset(feature_type, \"ITWtest\")\n",
    "ITW_test_loader = DataLoader(ITW_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test EER: {compute_EER(model, ITW_test_loader)}\")\n",
    "test_loss, test_accuracy = validate(ITW_test_loader)\n",
    "print(f\"Testing loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "\n",
    "# expected to be quite low, though obvious overfitting at current settings\n",
    "print(f\"Train EER: {compute_EER(model, FoR_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj420",
   "language": "python",
   "name": "proj420"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

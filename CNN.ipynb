{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEtR8P8MGhSX"
   },
   "source": [
    "# Processing for local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5S5KWJQSHn3z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#!tar -xf data/for-rerec.tar.gz -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xbEPVigKihN",
    "outputId": "2aefed60-6275-444c-f190-753329d620b2"
   },
   "outputs": [],
   "source": [
    "#ls data/for-rerecorded/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSWk1DLnIi_O",
    "outputId": "7747b4d1-d172-4189-d0fd-bc70149bf201"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision librosa matplotlib tqdm pandas tensorboard argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8omdaYcFI6hU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import zipfile\n",
    "import sys\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUWaXDsKNQ31"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7wm4V3FxPjGC"
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000  # Sampling rate\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5DdJBRQqNS9C"
   },
   "outputs": [],
   "source": [
    "# TODO: Make it so each output is \"513-dimensional\" as with the reference paper\n",
    "#\n",
    "# https://arxiv.org/pdf/2203.16263\n",
    "\n",
    "def compute_spectrograms(path):\n",
    "    y, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    fixed_length = 2 * SAMPLE_RATE\n",
    "    if len(y) < fixed_length:\n",
    "        y = np.pad(y, (0, fixed_length - len(y)))\n",
    "    else:\n",
    "        y = y[:fixed_length]\n",
    "\n",
    "    cqt = librosa.cqt(y, sr=sr)\n",
    "    cqt_spec = librosa.amplitude_to_db(np.abs(cqt), ref=np.max)\n",
    "\n",
    "    stft = librosa.stft(y)\n",
    "    log_spec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "    mel_spec = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "    return cqt_spec, log_spec, mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = {\n",
    "    'training_fake': 'data/for-rerecorded/training/fake/',\n",
    "    'testing_fake': 'data/for-rerecorded/testing/fake/',\n",
    "    'validation_fake': 'data/for-rerecorded/validation/fake/',\n",
    "    'training_real': 'data/for-rerecorded/training/real/',\n",
    "    'testing_real': 'data/for-rerecorded/testing/real/',\n",
    "    'validation_real': 'data/for-rerecorded/validation/real/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6PzYHa5TqHT",
    "outputId": "c364cca2-105e-4aab-9763-0f2e211e8443"
   },
   "outputs": [],
   "source": [
    "def process_directory(directory, output_dir):\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.wav'):\n",
    "      audio_path = os.path.join(directory, filename)\n",
    "      cqt, log, mel = compute_spectrograms(audio_path)\n",
    "\n",
    "      base_name = os.path.splitext(filename)[0]\n",
    "      # Save spectrograms as numpy arrays\n",
    "      np.save(f\"{output_dir}/{base_name}_cqt.npy\", cqt)\n",
    "      np.save(f\"{output_dir}/{base_name}_log.npy\", log)\n",
    "      np.save(f\"{output_dir}/{base_name}_mel.npy\", mel)\n",
    "\n",
    "compute_specs = False\n",
    "if compute_specs:\n",
    "    for set_name, directory in data_dirs.items():\n",
    "      output_dir = f'data/spectrograms/{set_name}_spectrograms'\n",
    "      process_directory(directory, output_dir)\n",
    "      print(f\"Processed {set_name} set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 63)\n",
      "(1025, 63)\n",
      "(128, 63)\n"
     ]
    }
   ],
   "source": [
    "# lets look at some data\n",
    "display_cqt = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_cqt.npy\"\n",
    "display_log = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_log.npy\"\n",
    "display_mel = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_mel.npy\"\n",
    "\n",
    "cqt_test = np.load(display_cqt)\n",
    "log_test = np.load(display_log)\n",
    "mel_test = np.load(display_mel)\n",
    "print(cqt_test.shape)\n",
    "print(log_test.shape)\n",
    "print(mel_test.shape)\n",
    "\n",
    "# for reference\n",
    "cqt_size = 84\n",
    "log_size = 1025\n",
    "mel_size = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-DJw8fFNZXj"
   },
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S2eATQYGNaUY"
   },
   "outputs": [],
   "source": [
    "class ResNet50Spectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50Spectrogram, self).__init__()\n",
    "\n",
    "        self.model = models.resnet50(weights=None)\n",
    "\n",
    "        original_conv = self.model.conv1\n",
    "        self.model.conv1 = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetSpectrogram(nn.Module):\n",
    "    def __init__(self, model_type):\n",
    "        super(EfficientNetSpectrogram, self).__init__()\n",
    "        \n",
    "        self.enet = None\n",
    "        \n",
    "        if model_type == \"b0\":\n",
    "            self.enet = models.efficientnet_b0(weights=None, num_classes=2)\n",
    "        elif model_type == 'b1':\n",
    "            self.enet = models.efficientnet_b1(weights=None, num_classes=2)\n",
    "            \n",
    "        \n",
    "        # We need to change the network to accept 1 channel instead of\n",
    "        # 3 because of our data.\n",
    "        original_conv = self.enet.features[0][0]\n",
    "        new_conv = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "        self.enet.features[0][0] = new_conv\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.enet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSpectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMSpectrogram, self).__init__()\n",
    "        \n",
    "        self.nlayer = 2\n",
    "        self.nhiddens = 256\n",
    "        \n",
    "        if feature_type == \"cqt\":\n",
    "            self.lstm = nn.LSTM(input_size=cqt_size, hidden_size=self.nhiddens, num_layers=self.nlayer, \n",
    "                                batch_first=True, dropout=0.3)\n",
    "        elif feature_type == \"log\":\n",
    "            self.lstm = nn.LSTM(input_size=log_size, hidden_size=self.nhiddens, num_layers=self.nlayer, \n",
    "                                batch_first=True, dropout=0.3)\n",
    "        elif feature_type == \"mel\":\n",
    "            self.lstm = nn.LSTM(input_size=mel_size, hidden_size=self.nhiddens, num_layers=self.nlayer, \n",
    "                                batch_first=True, dropout=0.3)\n",
    "            \n",
    "        self.fc = nn.Linear(self.nhiddens, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        # features are in wrong order for lstm\n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "        x, (h_o, c_o) = self.lstm(x)\n",
    "        \n",
    "        h_o = h_o.squeeze(0)\n",
    "        if self.nlayer > 1:\n",
    "            h_o = h_o[-1]\n",
    "        x = self.fc(h_o)\n",
    "        x = x.squeeze(-1)\n",
    "        \n",
    "        #x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#################################################################\n",
    "##                                                             ##\n",
    "## All of the code in this cell is from the RawNet2 repository ##\n",
    "##            https://github.com/Jungjee/RawNet                ##\n",
    "##                                                             ##\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch.utils import data\n",
    "from collections import OrderedDict\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FRM(nn.Module):\n",
    "    def __init__(self, nb_dim, do_add = True, do_mul = True):\n",
    "        super(FRM, self).__init__()\n",
    "        self.fc = nn.Linear(nb_dim, nb_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.do_add = do_add\n",
    "        self.do_mul = do_mul\n",
    "    def forward(self, x):\n",
    "        y = F.adaptive_avg_pool1d(x, 1).view(x.size(0), -1)\n",
    "        y = self.sig(self.fc(y)).view(x.size(0), x.size(1), -1)\n",
    "\n",
    "        if self.do_mul: x = x * y\n",
    "        if self.do_add: x = x + y\n",
    "        return x\n",
    "\n",
    "class Residual_block_wFRM(nn.Module):\n",
    "    def __init__(self, nb_filts, first = False):\n",
    "        super(Residual_block_wFRM, self).__init__()\n",
    "        self.first = first\n",
    "        if not self.first:\n",
    "            self.bn1 = nn.BatchNorm1d(num_features = nb_filts[0])\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.lrelu_keras = nn.LeakyReLU(negative_slope=0.3)\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels = nb_filts[0],\n",
    "            out_channels = nb_filts[1],\n",
    "            kernel_size = 3,\n",
    "            padding = 1,\n",
    "            stride = 1)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features = nb_filts[1])\n",
    "        self.conv2 = nn.Conv1d(in_channels = nb_filts[1],\n",
    "            out_channels = nb_filts[1],\n",
    "            padding = 1,\n",
    "            kernel_size = 3,\n",
    "            stride = 1)\n",
    "        \n",
    "        if nb_filts[0] != nb_filts[1]:\n",
    "            self.downsample = True\n",
    "            self.conv_downsample = nn.Conv1d(in_channels = nb_filts[0],\n",
    "                out_channels = nb_filts[1],\n",
    "                padding = 0,\n",
    "                kernel_size = 1,\n",
    "                stride = 1)\n",
    "            \n",
    "        else:\n",
    "            self.downsample = False\n",
    "        self.mp = nn.MaxPool1d(3)\n",
    "        self.frm = FRM(\n",
    "            nb_dim = nb_filts[1],\n",
    "            do_add = True,\n",
    "            do_mul = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if not self.first:\n",
    "            out = self.bn1(x)\n",
    "            out = self.lrelu_keras(out)\n",
    "        else:\n",
    "            out = x\n",
    "            \n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.lrelu_keras(out)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            identity = self.conv_downsample(identity)\n",
    "            \n",
    "        out += identity\n",
    "        out = self.mp(out)\n",
    "        out = self.frm(out)\n",
    "        return out\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(features))\n",
    "        self.beta = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "\n",
    "class SincConv_fast(nn.Module):\n",
    "    \"\"\"Sinc-based convolution\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : `int`\n",
    "        Number of input channels. Must be 1.\n",
    "    out_channels : `int`\n",
    "        Number of filters.\n",
    "    kernel_size : `int`\n",
    "        Filter length.\n",
    "    sample_rate : `int`, optional\n",
    "        Sample rate. Defaults to 16000.\n",
    "    Usage\n",
    "    -----\n",
    "    See `torch.nn.Conv1d`\n",
    "    Reference\n",
    "    ---------\n",
    "    Mirco Ravanelli, Yoshua Bengio,\n",
    "    \"Speaker Recognition from raw waveform with SincNet\".\n",
    "    https://arxiv.org/abs/1808.00158\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def to_mel(hz):\n",
    "        return 2595 * np.log10(1 + hz / 700)\n",
    "\n",
    "    @staticmethod\n",
    "    def to_hz(mel):\n",
    "        return 700 * (10 ** (mel / 2595) - 1)\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
    "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n",
    "\n",
    "        super(SincConv_fast,self).__init__()\n",
    "\n",
    "        if in_channels != 1:\n",
    "            #msg = (f'SincConv only support one input channel '\n",
    "            #       f'(here, in_channels = {in_channels:d}).')\n",
    "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
    "        if kernel_size%2==0:\n",
    "            self.kernel_size=self.kernel_size+1\n",
    "            \n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        if bias:\n",
    "            raise ValueError('SincConv does not support bias.')\n",
    "        if groups > 1:\n",
    "            raise ValueError('SincConv does not support groups.')\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        self.min_low_hz = min_low_hz\n",
    "        self.min_band_hz = min_band_hz\n",
    "\n",
    "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
    "        low_hz = 30\n",
    "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
    "\n",
    "        mel = np.linspace(self.to_mel(low_hz),\n",
    "                          self.to_mel(high_hz),\n",
    "                          self.out_channels + 1)\n",
    "        hz = self.to_hz(mel)\n",
    "        \n",
    "\n",
    "        # filter lower frequency (out_channels, 1)\n",
    "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
    "\n",
    "        # filter frequency band (out_channels, 1)\n",
    "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
    "\n",
    "        # Hamming window\n",
    "        #self.window_ = torch.hamming_window(self.kernel_size)\n",
    "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
    "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
    "\n",
    "        # (1, kernel_size/2)\n",
    "        n = (self.kernel_size - 1) / 2.0\n",
    "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
    "            Batch of waveforms.\n",
    "        Returns\n",
    "        -------\n",
    "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
    "            Batch of sinc filters activations.\n",
    "        \"\"\"\n",
    "\n",
    "        self.n_ = self.n_.to(waveforms.device)\n",
    "\n",
    "        self.window_ = self.window_.to(waveforms.device)\n",
    "\n",
    "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
    "        \n",
    "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
    "        band=(high-low)[:,0]\n",
    "        \n",
    "        f_times_t_low = torch.matmul(low, self.n_)\n",
    "        f_times_t_high = torch.matmul(high, self.n_)\n",
    "\n",
    "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
    "        band_pass_center = 2*band.view(-1,1)\n",
    "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
    "        \n",
    "        \n",
    "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
    "\n",
    "        \n",
    "        band_pass = band_pass / (2*band[:,None])\n",
    "        \n",
    "\n",
    "        self.filters = (band_pass).view(\n",
    "            self.out_channels, 1, self.kernel_size)\n",
    "\n",
    "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
    "                        padding=self.padding, dilation=self.dilation,\n",
    "                         bias=None, groups=1) \n",
    "    \n",
    "class RawNet2(nn.Module):\n",
    "    def __init__(self, d_args):\n",
    "        super(RawNet2, self).__init__()\n",
    "\n",
    "        self.ln = LayerNorm(d_args['nb_samp'])\n",
    "        self.first_conv = SincConv_fast(in_channels = d_args['in_channels'],\n",
    "            out_channels = d_args['filts'][0],\n",
    "            kernel_size = d_args['first_conv']\n",
    "            )\n",
    "\n",
    "        self.first_bn = nn.BatchNorm1d(num_features = d_args['filts'][0])\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.lrelu_keras = nn.LeakyReLU(negative_slope = 0.3)\n",
    "        \n",
    "        self.block0 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][1], first = True))\n",
    "        self.block1 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][1]))\n",
    " \n",
    "        self.block2 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\n",
    "        d_args['filts'][2][0] = d_args['filts'][2][1]\n",
    "        self.block3 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\n",
    "        self.block4 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\n",
    "        self.block5 = nn.Sequential(Residual_block_wFRM(nb_filts = d_args['filts'][2]))\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.bn_before_gru = nn.BatchNorm1d(num_features = d_args['filts'][2][-1])\n",
    "        self.gru = nn.GRU(input_size = d_args['filts'][2][-1],\n",
    "            hidden_size = d_args['gru_node'],\n",
    "            num_layers = d_args['nb_gru_layer'],\n",
    "            batch_first = True)\n",
    "\n",
    "        \n",
    "        self.fc1_gru = nn.Linear(in_features = d_args['gru_node'],\n",
    "            out_features = d_args['nb_fc_node'])\n",
    "        self.fc2_gru = nn.Linear(in_features = d_args['nb_fc_node'],\n",
    "            out_features = d_args['nb_classes'],\n",
    "            bias = True)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, y = 0, is_test=False):\n",
    "        #follow sincNet recipe\n",
    "        nb_samp = x.shape[0]\n",
    "        len_seq = x.shape[2]\n",
    "        x = self.ln(x)\n",
    "        x=x.view(nb_samp,1,len_seq)\n",
    "        x = F.max_pool1d(torch.abs(self.first_conv(x)), 3)\n",
    "        x = self.first_bn(x)\n",
    "        x = self.lrelu_keras(x)\n",
    "        \n",
    "        x = self.block0(x)\n",
    "        x = self.block1(x)\n",
    "\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "\n",
    "        x = self.bn_before_gru(x)\n",
    "        x = self.lrelu_keras(x)\n",
    "        x = x.permute(0, 2, 1)  #(batch, filt, time) >> (batch, time, filt)\n",
    "        self.gru.flatten_parameters()\n",
    "        x, _ = self.gru(x)\n",
    "        x = x[:,-1,:]\n",
    "        code = self.fc1_gru(x)\n",
    "        if is_test: return code\n",
    "        \n",
    "        code_norm = code.norm(p=2,dim=1, keepdim=True) / 10.\n",
    "        code = torch.div(code, code_norm)\n",
    "        out = self.fc2_gru(code)\n",
    "        return out\n",
    "    \n",
    "#################################################################\n",
    "#################################################################\n",
    "##                                                             ##\n",
    "## All of the code in this cell is from the RawNet2 repository ##\n",
    "##            https://github.com/Jungjee/RawNet                ##\n",
    "##                                                             ##\n",
    "#################################################################\n",
    "#################################################################\n",
    "\n",
    "import argparse\n",
    "\n",
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "       return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \n",
    "    if '-f' in sys.argv:\n",
    "        jupyter_arg_index = sys.argv.index('-f')\n",
    "        del sys.argv[jupyter_arg_index:jupyter_arg_index+2]\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    #DNN args\n",
    "    parser.add_argument('-m_first_conv', type = int, default = 251)\n",
    "    parser.add_argument('-m_in_channels', type = int, default = 1)\n",
    "    parser.add_argument('-m_filts', type = list, default = [128, [128,128], [128,256], [256,256]])\n",
    "    parser.add_argument('-m_blocks', type = list, default = [2, 4])\n",
    "    parser.add_argument('-m_nb_fc_att_node', type = list, default = [1])\n",
    "    parser.add_argument('-m_nb_fc_node', type = int, default = 1024)\n",
    "    parser.add_argument('-m_gru_node', type = int, default = 1024)\n",
    "    parser.add_argument('-m_nb_gru_layer', type = int, default = 1)\n",
    "    parser.add_argument('-m_nb_samp', type = int, default = 59049)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    args.model = {}\n",
    "    for k, v in vars(args).items():\n",
    "        if k[:2] == 'm_':\n",
    "            print(k, v)\n",
    "            args.model[k[2:]] = v\n",
    "    return args\n",
    "\n",
    "#################################################################\n",
    "#################################################################\n",
    "##                                                             ##\n",
    "## All of the code in this cell is from the RawNet2 repository ##\n",
    "##            https://github.com/Jungjee/RawNet                ##\n",
    "##                                                             ##\n",
    "#################################################################\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18Spectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18Spectrogram, self).__init__()\n",
    "\n",
    "        self.model = models.resnet18(weights=None)\n",
    "\n",
    "        original_conv = self.model.conv1\n",
    "        self.model.conv1 = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecDataset(Dataset):\n",
    "    # data_type is one of 'cqt', 'log', 'mel'\n",
    "    #\n",
    "    # loader_type is one of 'train', 'validation', 'test'\n",
    "    def __init__(self, data_type, loader_type):\n",
    "        \n",
    "        root = os.getcwd()\n",
    "        data_root = os.path.join(root, 'data/spectrograms')\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        real_folder = None\n",
    "        fake_folder = None\n",
    "\n",
    "        # get the folder\n",
    "        if loader_type == \"train\":\n",
    "            real_folder = os.path.join(data_root, 'training_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'training_fake_spectrograms')\n",
    "        elif loader_type == \"validation\":\n",
    "            real_folder = os.path.join(data_root, 'validation_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'validation_fake_spectrograms')\n",
    "        elif loader_type == \"test\":\n",
    "            real_folder = os.path.join(data_root, 'testing_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'testing_fake_spectrograms')\n",
    "        elif loader_type == \"ITWFull\":\n",
    "            real_folder = os.path.join(data_root, 'ITWfull_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'ITWfull_fake_spectrograms')\n",
    "        else:\n",
    "            # Should never occur.\n",
    "            pass\n",
    "        \n",
    "        real_files = []\n",
    "        fake_files = []\n",
    "        \n",
    "        # now we have the folder given the loader type, collect\n",
    "        # the data required for the loader.\n",
    "        \n",
    "        # get real example filenames\n",
    "        suffix = f\"{data_type}.npy\"\n",
    "        for filename in os.listdir(real_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(real_folder, filename)):\n",
    "                this_filepath = os.path.join(real_folder, filename)\n",
    "                real_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Real examples for {data_type} {loader_type}: {len(real_files)}\")\n",
    "        \n",
    "        # get fake example filenames\n",
    "        suffix = f\"{data_type}.npy\"\n",
    "        for filename in os.listdir(fake_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(fake_folder, filename)):\n",
    "                this_filepath = os.path.join(fake_folder, filename)\n",
    "                fake_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Fake examples for {data_type} {loader_type}: {len(fake_files)}\")\n",
    "        \n",
    "        label_val_false = 0\n",
    "        label_val_true = 1\n",
    "        if model_type == \"LSTM\":\n",
    "            label_val_false = float(0)\n",
    "            label_val_true = float(1)\n",
    "        \n",
    "        # load the data into memory\n",
    "        #\n",
    "        # if we need to work with a larger dataset, you might need to\n",
    "        # alter this to be lazy loading instead, but it fits in my main memory\n",
    "        # because of how much I currently have.\n",
    "        for real_file in real_files:\n",
    "            rf_data = torch.tensor(np.load(real_file))\n",
    "            rf_data = rf_data.unsqueeze(0)\n",
    "            if resizing == True:\n",
    "                rf_data = rf_data.unsqueeze(0)\n",
    "                rf_data = F.interpolate(rf_data, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "                rf_data = rf_data.squeeze(0)\n",
    "            self.data.append((rf_data,label_val_true))\n",
    "            \n",
    "        for fake_file in fake_files:\n",
    "            ff_data = torch.tensor(np.load(fake_file))\n",
    "            ff_data = ff_data.unsqueeze(0)\n",
    "            if resizing == True:\n",
    "                ff_data = ff_data.unsqueeze(0)\n",
    "                ff_data = F.interpolate(ff_data, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "                ff_data = ff_data.squeeze(0)\n",
    "            self.data.append((ff_data, label_val_false))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # return the data and the label\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawnetWaveformDataset(Dataset):\n",
    "    def __init__(self, loader_type):\n",
    "        \n",
    "        root = os.getcwd()\n",
    "        data_root = None\n",
    "        real_folder = None\n",
    "        fake_folder = None\n",
    "        \n",
    "        # get the folder\n",
    "        if loader_type == \"train\":\n",
    "            data_root = os.path.join(root, 'data/for-rerecorded/training')\n",
    "            real_folder = os.path.join(data_root, 'real')\n",
    "            fake_folder = os.path.join(data_root, 'fake')\n",
    "        elif loader_type == \"validation\":\n",
    "            data_root = os.path.join(root, 'data/for-rerecorded/validation')\n",
    "            real_folder = os.path.join(data_root, 'real')\n",
    "            fake_folder = os.path.join(data_root, 'fake')\n",
    "        elif loader_type == \"test\":\n",
    "            data_root = os.path.join(root, 'data/for-rerecorded/testing')\n",
    "            real_folder = os.path.join(data_root, 'real')\n",
    "            fake_folder = os.path.join(data_root, 'fake')\n",
    "        elif loader_type == \"ITWFull\":\n",
    "            data_root = os.path.join(root, 'data/release_in_the_wild')\n",
    "            real_folder = os.path.join(data_root, 'real')\n",
    "            fake_folder = os.path.join(data_root, 'fake')\n",
    "        else:\n",
    "            # Should never occur.\n",
    "            pass\n",
    "        \n",
    "        self.real_files = []\n",
    "        self.fake_files = []\n",
    "        \n",
    "        # get real example filenames\n",
    "        suffix = f\".wav\"\n",
    "        for filename in os.listdir(real_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(real_folder, filename)):\n",
    "                this_filepath = os.path.join(real_folder, filename)\n",
    "                self.real_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Real examples for raw waveform {loader_type}: {len(self.real_files)}\")\n",
    "        \n",
    "        # get fake example filenames\n",
    "        suffix = f\".wav\"\n",
    "        for filename in os.listdir(fake_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(fake_folder, filename)):\n",
    "                this_filepath = os.path.join(fake_folder, filename)\n",
    "                self.fake_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Fake examples for raw waveform {loader_type}: {len(self.fake_files)}\")\n",
    "            \n",
    "        # load the raw waveform data\n",
    "        #\n",
    "        # We follow the dataloader from the RawNet implementation\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        target_samples = 59049\n",
    "        \n",
    "        for real_file in self.real_files:\n",
    "            X, sr = sf.read(real_file)\n",
    "            X = X.astype(np.float64)\n",
    "            X = X.reshape(1, -1)\n",
    "            \n",
    "            # prepare the .wav file to be 59049 samples as is needed\n",
    "            n_samples = X.shape[1]\n",
    "            if n_samples < target_samples:\n",
    "                n_duplicates = int(target_samples / n_samples) + 1\n",
    "                X = np.tile(X, (1, n_duplicates))[:, :target_samples]\n",
    "                \n",
    "            elif n_samples > target_samples:\n",
    "                start = np.random.randint(0, n_samples - target_samples)\n",
    "                X = X[:, start : start + target_samples]\n",
    "                \n",
    "            # now append the data\n",
    "            X = X.astype(np.float32)\n",
    "            self.data.append((X, 1))\n",
    "            \n",
    "        for fake_file in self.fake_files:\n",
    "            X, sr = sf.read(real_file)\n",
    "            X = X.astype(np.float64)\n",
    "            X = X.reshape(1, -1)\n",
    "            \n",
    "            # prepare the .wav file to be 59049 samples as is needed\n",
    "            n_samples = X.shape[1]\n",
    "            if n_samples < target_samples:\n",
    "                n_duplicates = int(target_samples / n_samples) + 1\n",
    "                X = np.tile(X, (1, n_duplicates))[:, :target_samples]\n",
    "                \n",
    "            elif n_samples > target_samples:\n",
    "                start = np.random.randint(0, n_samples - target_length)\n",
    "                X = X[:, start : start + target_length]\n",
    "                \n",
    "            # append\n",
    "            X = X.astype(np.float32)\n",
    "            self.data.append((X, 0))\n",
    "            \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # return the data and the label\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_collate(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    data = [d for d in data]\n",
    "    \n",
    "    max_length = max(d.shape[2] for d in data)\n",
    "    \n",
    "    padded = []\n",
    "    if resizing == False:\n",
    "        for d in data:\n",
    "            # total padding needed, >= 0\n",
    "            padding = max_length - d.shape[2]\n",
    "        \n",
    "            padded_d = None\n",
    "            if padding > 0:\n",
    "                # add zero's (silence) to match rest of batch\n",
    "                padded_data = F.pad(d, (0,padding))\n",
    "            \n",
    "            else:\n",
    "                # already max length\n",
    "                padded_data = d\n",
    "            padded.append(padded_data)\n",
    "    else:\n",
    "        # if resizing was true, we don't need to pad, everything is of the same shape\n",
    "        padded = data\n",
    "    \n",
    "    '''\n",
    "    for p in padded:\n",
    "        r = p.unsqueeze(0)\n",
    "        r = F.interpolate(r, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "        r = r.squeeze(0)\n",
    "        resized.append(r)\n",
    "    '''\n",
    "    \n",
    "    # stack properly now that everything is padded\n",
    "    padded = torch.stack(padded, dim=0)\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return padded, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = [0]\n",
    "#std = [1]\n",
    "\n",
    "# deal with this later\n",
    "#\n",
    "# we should also probably compute the mean and std manually instead of assuming they correctly\n",
    "# normalized it, since this is the re-recorded dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(mean, std)\n",
    "  ])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "####################################################\n",
    "# <CHANGE ME> if you want to use different features!\n",
    "####################################################\n",
    "feature_type = \"cqt\"\n",
    "\n",
    "####################################################\n",
    "# <CHANGE ME> if you want to use resizing!\n",
    "#\n",
    "# We need to resize to, for example, (224, 224)\n",
    "####################################################\n",
    "resizing = True\n",
    "dims_resize = (224, 224)\n",
    "\n",
    "#model_type = \"enet\"\n",
    "#model_type = \"res\"\n",
    "#model_type = \"LSTM\"\n",
    "#model_type = 'raw2' # very, very long time to train\n",
    "#model_type = \"res18\"\n",
    "model_type = 'enet1'\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = None\n",
    "RawNet2_args = None\n",
    "\n",
    "if model_type == \"LSTM\":\n",
    "    model = LSTMSpectrogram()\n",
    "elif model_type == \"enet\":\n",
    "    model =  EfficientNetSpectrogram(\"b0\")\n",
    "elif model_type == \"res\":\n",
    "    model = ResNet50Spectrogram()\n",
    "elif model_type == 'raw2':\n",
    "    RawNet2_args = get_args()\n",
    "    # just do this manually\n",
    "    RawNet2_args.model['nb_classes'] = 2\n",
    "    model = RawNet2(RawNet2_args.model)\n",
    "elif model_type == 'res18':\n",
    "    model = ResNet18Spectrogram()\n",
    "elif model_type == 'enet1':\n",
    "    model = EfficientNetSpectrogram(\"b1\")\n",
    "    \n",
    "model = model.to(device)\n",
    "\n",
    "#epochs = 100\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "weight_decay = 5e-4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if model_type == \"LSTM\":\n",
    "    resizing = False\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif model_type == \"raw2\":\n",
    "    resizing = False\n",
    "    \n",
    "    \n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "\n",
    "FoR_train_dataset = None\n",
    "FoR_val_dataset = None\n",
    "FoR_test_dataset = None\n",
    "\n",
    "FoR_train_loader = None\n",
    "FoR_val_loader = None\n",
    "FoR_test_loader = None\n",
    "\n",
    "# data loaders\n",
    "if model_type == \"raw2\":\n",
    "    FoR_train_dataset = RawnetWaveformDataset(\"train\")\n",
    "    FoR_val_dataset = RawnetWaveformDataset(\"validation\")\n",
    "    FoR_test_dataset = RawnetWaveformDataset(\"test\")\n",
    "    FoR_train_loader = DataLoader(FoR_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    FoR_val_loader = DataLoader(FoR_val_dataset, batch_size=batch_size, shuffle=True)\n",
    "    FoR_test_loader = DataLoader(FoR_test_dataset, batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    FoR_train_dataset = SpecDataset(feature_type, \"train\")\n",
    "    FoR_val_dataset = SpecDataset(feature_type, \"validation\")\n",
    "    FoR_test_dataset = SpecDataset(feature_type, \"test\")\n",
    "    FoR_train_loader = DataLoader(FoR_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "    FoR_val_loader = DataLoader(FoR_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "    FoR_test_loader = DataLoader(FoR_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to compute the equal error rate as one of our metrics.\n",
    "def compute_EER(model, loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            waveform, labels = data\n",
    "            \n",
    "            waveform = waveform.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            out = model(waveform)\n",
    "            if model_type == \"LSTM\":\n",
    "                out = torch.sigmoid(out)\n",
    "            else:\n",
    "                out = torch.softmax(out, dim=1)\n",
    "                # take the positive class labels\n",
    "                out = out[:,1]\n",
    "            \n",
    "            all_scores.extend(out.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # use sklearn to compute this for us\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "    \n",
    "    # definition\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # find closest threshold\n",
    "    eer_thresh = np.nanargmin(np.abs(fpr-fnr))\n",
    "    EER = (fpr[eer_thresh] + fnr[eer_thresh])/2\n",
    "    \n",
    "    return EER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    \n",
    "    for data in loader:\n",
    "        waveform, labels = data\n",
    "        waveform = waveform.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # basic pytorch boilerplate\n",
    "        out = model(waveform)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    training_loss = training_loss / len(loader)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader):\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            waveform, labels = data\n",
    "            \n",
    "            waveform = waveform.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            out = model(waveform)\n",
    "            loss = criterion(out, labels)\n",
    "            \n",
    "            validation_loss += loss.item()\n",
    "            \n",
    "            # count correct predictions\n",
    "            preds = None\n",
    "            if model_type == \"LSTM\":\n",
    "                preds = (out > 0).long()\n",
    "            else:\n",
    "                preds = out.argmax(dim=1)\n",
    "            \n",
    "            n_correct = n_correct + (preds == labels).sum().item()\n",
    "            n_total = n_total + labels.size(0)\n",
    "            \n",
    "    validation_loss = validation_loss / len(loader)\n",
    "    accuracy = n_correct / n_total\n",
    "    \n",
    "    return validation_loss, accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference paper uses patience = 5\n",
    "patience = 5\n",
    "best_validation_loss = 10000.0\n",
    "fail_count = 0\n",
    "\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    training_loss = train(FoR_train_loader)\n",
    "    print(f\"[Epoch {epoch}] Training Loss: {training_loss}\")\n",
    "    \n",
    "    training_losses.append(training_loss)\n",
    "    \n",
    "    validation_loss, val_accuracy = validate(FoR_val_loader)    \n",
    "    print(f\"[Epoch {epoch}] Validation Loss: {validation_loss} Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    val_losses.append(validation_loss)\n",
    "    \n",
    "    test_loss, test_accuracy = validate(FoR_test_loader)\n",
    "    print(f\"[DEBUG Epoch {epoch}] Test Loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        fail_count = 0\n",
    "    else:\n",
    "        # increment number of epochs of no improvement\n",
    "        fail_count = fail_count + 1\n",
    "        \n",
    "    if fail_count >= patience:\n",
    "        print(f\"Triggering early breaking on epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test EER: {compute_EER(model, FoR_test_loader)}\")\n",
    "test_loss, test_accuracy = validate(FoR_test_loader)\n",
    "print(f\"Testing loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "\n",
    "# expected to be quite low, though obvious overfitting at current settings\n",
    "print(f\"Train EER: {compute_EER(model, FoR_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(training_losses)), training_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\", marker='s')\n",
    "plt.plot(range(len(test_losses)), test_losses, label=\"Test Loss\", marker='x')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process entire ITW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"data/release_in_the_wild\"):\n",
    "    with zipfile.ZipFile('data/release_in_the_wild.zip') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_csv = 'data/release_in_the_wild/meta.csv'\n",
    "\n",
    "df = pd.read_csv(src_csv)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    name = row['file']\n",
    "    label = str(row['label'])\n",
    "\n",
    "    src_path = os.path.join('data/release_in_the_wild', name)\n",
    "    dst_dir = os.path.join('data/release_in_the_wild', label)\n",
    "    dst_path = os.path.join(dst_dir, name)\n",
    "\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(src_path):\n",
    "        shutil.move(src_path, dst_path)\n",
    "\n",
    "os.rename('data/release_in_the_wild/bona-fide', 'data/release_in_the_wild/real')\n",
    "os.rename('data/release_in_the_wild/spoof', 'data/release_in_the_wild/fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory, output_dir):\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.wav'):\n",
    "      audio_path = os.path.join(directory, filename)\n",
    "      cqt, log, mel = compute_spectrograms(audio_path)\n",
    "\n",
    "      base_name = os.path.splitext(filename)[0]\n",
    "      # Save spectrograms as numpy arrays\n",
    "      np.save(f\"{output_dir}/{base_name}_cqt.npy\", cqt)\n",
    "      np.save(f\"{output_dir}/{base_name}_log.npy\", log)\n",
    "      np.save(f\"{output_dir}/{base_name}_mel.npy\", mel)\n",
    "\n",
    "data_dirs = {\n",
    "    'ITWfull_real': 'data/release_in_the_wild/real',\n",
    "    'ITWfull_fake': 'data/release_in_the_wild/fake/'\n",
    "}\n",
    "if compute_specs:\n",
    "    for set_name, directory in data_dirs.items():\n",
    "        output_dir = f'data/spectrograms/{set_name}_spectrograms'\n",
    "        process_directory(directory, output_dir)\n",
    "        print(f\"Processed {set_name} set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing some of the data\n",
    "ITW_display_cqt = \"data/spectrograms/ITWfull_real_spectrograms/5_cqt.npy\"\n",
    "ITW_display_log = \"data/spectrograms/ITWfull_real_spectrograms/5_log.npy\"\n",
    "ITW_display_mel = \"data/spectrograms/ITWfull_real_spectrograms/5_mel.npy\"\n",
    "\n",
    "ITW_cqt_test = np.load(display_cqt)\n",
    "ITW_log_test = np.load(display_log)\n",
    "ITW_mel_test = np.load(display_mel)\n",
    "print(ITW_cqt_test.shape)\n",
    "print(ITW_log_test.shape)\n",
    "print(ITW_mel_test.shape)\n",
    "\n",
    "# for reference, should be the same as before\n",
    "ITW_cqt_size = 84\n",
    "ITW_log_size = 1025\n",
    "ITW_mel_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the FoR trained model on the ITW dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already defined above\n",
    "# feature_type = \"cqt\"\n",
    "# resizing = True\n",
    "# dims_resize = (224, 224)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ITW_full_dataset = None\n",
    "ITW_full_loader = None\n",
    "\n",
    "if model_type == 'raw2':\n",
    "    ITW_full_dataset = RawnetWaveformDataset(\"ITWFull\")\n",
    "    ITW_full_loader = DataLoader(ITW_full_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "else:\n",
    "    ITW_full_dataset = SpecDataset(feature_type, \"ITWFull\")\n",
    "    ITW_full_loader = DataLoader(ITW_full_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ITW Test EER: {compute_EER(model, ITW_full_loader)}\")\n",
    "test_loss, test_accuracy = validate(ITW_full_loader)\n",
    "print(f\"ITW Testing loss: {test_loss} Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning from FoR to ITW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most of the settings should be kept the same from previous training, because we are\n",
    "# using the same model.\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = 0.8 * len(ITW_full_dataset)\n",
    "val_size = 0.1 * len(ITW_full_dataset)\n",
    "train_size = int(train_size)\n",
    "val_size = int(val_size)\n",
    "\n",
    "test_size = len(ITW_full_dataset) - val_size - train_size\n",
    "\n",
    "# now they should all sum to ITW_full_dataset, do the split\n",
    "\n",
    "ITW_train, ITW_val, ITW_test = random_split(ITW_full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "weight_decay = 5e-4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "\n",
    "ITW_train_loader = DataLoader(ITW_train, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "ITW_val_loader = DataLoader(ITW_val, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "ITW_test_loader = DataLoader(ITW_test, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "\n",
    "print(len(ITW_train_loader.dataset))\n",
    "print(len(ITW_val_loader.dataset))\n",
    "print(len(ITW_test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same loop, but for our ITW transfer learning.\n",
    "\n",
    "patience = 5\n",
    "best_validation_loss = 10000.0\n",
    "fail_count = 0\n",
    "\n",
    "TL_training_losses = []\n",
    "TL_val_losses = []\n",
    "# TL_test_losses = []\n",
    "\n",
    "print(\"Starting transfer learning from FoR dataset model to ITW\")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    training_loss = train(ITW_train_loader)\n",
    "    print(f\"[Epoch {epoch}] Training Loss: {training_loss}\")\n",
    "    \n",
    "    TL_training_losses.append(training_loss)\n",
    "    \n",
    "    validation_loss, val_accuracy = validate(ITW_val_loader)    \n",
    "    print(f\"[Epoch {epoch}] Validation Loss: {validation_loss} Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    TL_val_losses.append(validation_loss)\n",
    "    \n",
    "    # test_loss, test_accuracy = validate(ITW_test_loader)\n",
    "    # print(f\"[DEBUG Epoch {epoch}] Test Loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # TL_test_losses.append(test_loss)\n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        fail_count = 0\n",
    "    else:\n",
    "        # increment number of epochs of no improvement\n",
    "        fail_count = fail_count + 1\n",
    "        \n",
    "    if fail_count >= patience:\n",
    "        print(f\"Triggering early breaking on epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Transfer Learning ITW Test EER: {compute_EER(model, ITW_test_loader)}\")\n",
    "test_loss, test_accuracy = validate(ITW_test_loader)\n",
    "print(f\"Testing loss: {test_loss} Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure ITW training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have data loaders, simply setup the same model and training procedures.\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(mean, std)\n",
    "  ])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# setup the model, exact same one as used prior with empty weights\n",
    "\n",
    "model = None\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "if model_type == \"LSTM\":\n",
    "    model = LSTMSpectrogram()\n",
    "elif model_type == \"enet\":\n",
    "    model =  EfficientNetSpectrogram(\"b0\")\n",
    "elif model_type == \"res\":\n",
    "    model = ResNet50Spectrogram()\n",
    "elif model_type == 'res18'\n",
    "    model = ResNet18Spectrogram()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "#epochs = 100\n",
    "epochs = 30\n",
    "weight_decay = 5e-4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if model_type == \"LSTM\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the ITW dataset with an empty model\n",
    "\n",
    "# Same loop, but for our ITW transfer learning.\n",
    "\n",
    "patience = 5\n",
    "best_validation_loss = 10000.0\n",
    "fail_count = 0\n",
    "\n",
    "ITW_training_losses = []\n",
    "ITW_val_losses = []\n",
    "# ITW_test_losses = []\n",
    "\n",
    "print(\"Starting pure ITW training using the same model type (with weights cleared)\")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    training_loss = train(ITW_train_loader)\n",
    "    print(f\"[Epoch {epoch}] Training Loss: {training_loss}\")\n",
    "    \n",
    "    ITW_training_losses.append(training_loss)\n",
    "    \n",
    "    validation_loss, val_accuracy = validate(ITW_val_loader)    \n",
    "    print(f\"[Epoch {epoch}] Validation Loss: {validation_loss} Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    ITW_val_losses.append(validation_loss)\n",
    "    \n",
    "    test_loss, test_accuracy = validate(ITW_test_loader)\n",
    "    # print(f\"[DEBUG Epoch {epoch}] Test Loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # ITW_test_losses.append(test_loss)\n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        fail_count = 0\n",
    "    else:\n",
    "        # increment number of epochs of no improvement\n",
    "        fail_count = fail_count + 1\n",
    "        \n",
    "    if fail_count >= patience:\n",
    "        print(f\"Triggering early breaking on epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pure ITW Test EER: {compute_EER(model, ITW_test_loader)}\")\n",
    "test_loss, test_accuracy = validate(ITW_test_loader)\n",
    "print(f\"Pure ITW Testing loss: {test_loss} Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark the inference time of the model (should be same across either training method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample data\n",
    "input_data, _ = next(iter(ITW_full_loader))\n",
    "input_data = input_data.to(device)\n",
    "\n",
    "# make sure model is in fastest cache\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        _ = model(input_data)\n",
    "        \n",
    "n_bench_runs = 1000\n",
    "run_times = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(n_bench_runs)):\n",
    "        # important to make sure each run is done sequentially\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        start = torch.cuda.Event(enable_timing = True)\n",
    "        end = torch.cuda.Event(enable_timing = True)\n",
    "        \n",
    "        start.record()\n",
    "        _ = model(input_data)\n",
    "        end.record()\n",
    "        \n",
    "        # important to make sure each run is done sequentially\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        run_times.append(start.elapsed_time(end))\n",
    "    \n",
    "average_rtime = sum(run_times) / n_bench_runs\n",
    "print(f'Average run time for batch of size {batch_size} on model {model_type} with features {feature_type}')\n",
    "print(f'{average_rtime} ms')\n",
    "print(f'Averages to {average_rtime / batch_size} ms per input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj420",
   "language": "python",
   "name": "proj420"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

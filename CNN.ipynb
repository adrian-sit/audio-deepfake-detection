{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEtR8P8MGhSX"
   },
   "source": [
    "# Processing for local training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5S5KWJQSHn3z"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#!tar -xf data/for-rerec.tar.gz -C data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xbEPVigKihN",
    "outputId": "2aefed60-6275-444c-f190-753329d620b2"
   },
   "outputs": [],
   "source": [
    "#ls data/for-rerecorded/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSWk1DLnIi_O",
    "outputId": "7747b4d1-d172-4189-d0fd-bc70149bf201"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision librosa matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8omdaYcFI6hU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUWaXDsKNQ31"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wm4V3FxPjGC"
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050  # Sampling rate\n",
    "N_MELS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5DdJBRQqNS9C"
   },
   "outputs": [],
   "source": [
    "# TODO: Make it so each output is \"513-dimensional\" as with the reference paper\n",
    "#\n",
    "# https://arxiv.org/pdf/2203.16263\n",
    "\n",
    "def compute_spectrograms(path):\n",
    "  y, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "\n",
    "  cqt = librosa.cqt(y, sr=sr)\n",
    "  cqt_spec = librosa.amplitude_to_db(np.abs(cqt), ref=np.max)\n",
    "\n",
    "  stft = librosa.stft(y)\n",
    "  log_spec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "\n",
    "  mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=N_MELS)\n",
    "  mel_spec = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "  return cqt_spec, log_spec, mel_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = {\n",
    "    'training_fake': 'data/for-rerecorded/training/fake/',\n",
    "    'testing_fake': 'data/for-rerecorded/testing/fake/',\n",
    "    'validation_fake': 'data/for-rerecorded/validation/fake/',\n",
    "    'training_real': 'data/for-rerecorded/training/real/',\n",
    "    'testing_real': 'data/for-rerecorded/testing/real/',\n",
    "    'validation_real': 'data/for-rerecorded/validation/real/',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6PzYHa5TqHT",
    "outputId": "c364cca2-105e-4aab-9763-0f2e211e8443"
   },
   "outputs": [],
   "source": [
    "def process_directory(directory, output_dir):\n",
    "  os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "  for filename in tqdm(os.listdir(directory)):\n",
    "    if filename.endswith('.wav'):\n",
    "      audio_path = os.path.join(directory, filename)\n",
    "      cqt, log, mel = compute_spectrograms(audio_path)\n",
    "\n",
    "      base_name = os.path.splitext(filename)[0]\n",
    "      # Save spectrograms as numpy arrays\n",
    "      np.save(f\"{output_dir}/{base_name}_cqt.npy\", cqt)\n",
    "      np.save(f\"{output_dir}/{base_name}_log.npy\", log)\n",
    "      np.save(f\"{output_dir}/{base_name}_mel.npy\", mel)\n",
    "\n",
    "compute_specs = False\n",
    "if compute_specs:\n",
    "    for set_name, directory in data_dirs.items():\n",
    "      output_dir = f'data/spectrograms/{set_name}_spectrograms'\n",
    "      process_directory(directory, output_dir)\n",
    "      print(f\"Processed {set_name} set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at some data\n",
    "display_cqt = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_cqt.npy\"\n",
    "display_log = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_log.npy\"\n",
    "display_mel = \"data/spectrograms/training_fake_spectrograms/recording1.wav_norm_mono_mel.npy\"\n",
    "\n",
    "cqt_test = np.load(display_cqt)\n",
    "log_test = np.load(display_log)\n",
    "mel_test = np.load(display_mel)\n",
    "print(cqt_test.shape)\n",
    "print(log_test.shape)\n",
    "print(mel_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-DJw8fFNZXj"
   },
   "source": [
    "# Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2eATQYGNaUY"
   },
   "outputs": [],
   "source": [
    "class ResNet50Spectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50Spectrogram, self).__init__()\n",
    "\n",
    "        self.model = models.resnet50(weights=None)\n",
    "\n",
    "        original_conv = self.model.conv1\n",
    "        self.model.conv1 = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetSpectrogram(nn.Module):\n",
    "    def __init__(self, model_type):\n",
    "        super(EfficientNetSpectrogram, self).__init__()\n",
    "        \n",
    "        self.enet = None\n",
    "        \n",
    "        if model_type == \"b0\":\n",
    "            self.enet = models.efficientnet_b0(weights=None, num_classes=2)\n",
    "            \n",
    "        \n",
    "        # We need to change the network to accept 1 channel instead of\n",
    "        # 3 because of our data.\n",
    "        original_conv = self.enet.features[0][0]\n",
    "        new_conv = nn.Conv2d(in_channels=1,\n",
    "                            out_channels=original_conv.out_channels,\n",
    "                            kernel_size = original_conv.kernel_size,\n",
    "                            stride = original_conv.stride,\n",
    "                            padding = original_conv.padding,\n",
    "                            bias = False)\n",
    "        self.enet.features[0][0] = new_conv\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.enet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSpectrogram(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMSpectrogram, self).__init__()\n",
    "        \n",
    "        # picking 128 as a starting point\n",
    "        self.lstm = nn.LSTM(input_size=84,hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        x = x.squeeze(1)\n",
    "        print(x.shape)\n",
    "        x = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecDataset(Dataset):\n",
    "    # data_type is one of 'cqt', 'log', 'mel'\n",
    "    #\n",
    "    # loader_type is one of 'train', 'validation', 'test'\n",
    "    def __init__(self, data_type, loader_type):\n",
    "        \n",
    "        root = os.getcwd()\n",
    "        data_root = os.path.join(root, 'data/spectrograms')\n",
    "        \n",
    "        self.data = []\n",
    "        \n",
    "        real_folder = None\n",
    "        fake_folder = None\n",
    "\n",
    "        # get the folder\n",
    "        if loader_type == \"train\":\n",
    "            real_folder = os.path.join(data_root, 'training_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'training_fake_spectrograms')\n",
    "        elif loader_type == \"validation\":\n",
    "            real_folder = os.path.join(data_root, 'validation_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'validation_fake_spectrograms')\n",
    "        elif loader_type == \"test\":\n",
    "            real_folder = os.path.join(data_root, 'testing_real_spectrograms')\n",
    "            fake_folder = os.path.join(data_root, 'testing_fake_spectrograms')\n",
    "        else:\n",
    "            # Should never occur.\n",
    "            pass\n",
    "        \n",
    "        real_files = []\n",
    "        fake_files = []\n",
    "        \n",
    "        # now we have the folder given the loader type, collect\n",
    "        # the data required for the loader.\n",
    "        \n",
    "        # get real example filenames\n",
    "        suffix = f\"{data_type}.npy\"\n",
    "        for filename in os.listdir(real_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(real_folder, filename)):\n",
    "                this_filepath = os.path.join(real_folder, filename)\n",
    "                real_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Real examples for {data_type} {loader_type}: {len(real_files)}\")\n",
    "        \n",
    "        # get fake example filenames\n",
    "        suffix = f\"{data_type}.npy\"\n",
    "        for filename in os.listdir(fake_folder):\n",
    "            # check if correct suffix and exists as a file\n",
    "            if filename.endswith(suffix) and os.path.isfile(os.path.join(fake_folder, filename)):\n",
    "                this_filepath = os.path.join(fake_folder, filename)\n",
    "                fake_files.append(this_filepath)\n",
    "                \n",
    "        print(f\"Fake examples for {data_type} {loader_type}: {len(fake_files)}\")\n",
    "        \n",
    "        \n",
    "        # load the data into memory\n",
    "        #\n",
    "        # if we need to work with a larger dataset, you might need to\n",
    "        # alter this to be lazy loading instead, but it fits in my main memory\n",
    "        # because of how much I currently have.\n",
    "        for real_file in real_files:\n",
    "            rf_data = torch.tensor(np.load(real_file))\n",
    "            rf_data = rf_data.unsqueeze(0)\n",
    "            if resizing == True:\n",
    "                rf_data = rf_data.unsqueeze(0)\n",
    "                rf_data = F.interpolate(rf_data, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "                rf_data = rf_data.squeeze(0)\n",
    "            self.data.append((rf_data,1))\n",
    "            \n",
    "        for fake_file in fake_files:\n",
    "            ff_data = torch.tensor(np.load(fake_file))\n",
    "            ff_data = ff_data.unsqueeze(0)\n",
    "            if resizing == True:\n",
    "                ff_data = ff_data.unsqueeze(0)\n",
    "                ff_data = F.interpolate(ff_data, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "                ff_data = ff_data.squeeze(0)\n",
    "            self.data.append((ff_data, 0))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        # return the data and the label\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_collate(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    data = [d for d in data]\n",
    "    \n",
    "    max_length = max(d.shape[2] for d in data)\n",
    "    \n",
    "    padded = []\n",
    "    if resizing == False:\n",
    "        for d in data:\n",
    "            # total padding needed, >= 0\n",
    "            padding = max_length - d.shape[2]\n",
    "        \n",
    "            padded_d = None\n",
    "            if padding > 0:\n",
    "                # add zero's (silence) to match rest of batch\n",
    "                padded_data = F.pad(d, (0,padding))\n",
    "            \n",
    "            else:\n",
    "                # already max length\n",
    "                padded_data = d\n",
    "            padded.append(padded_data)\n",
    "    else:\n",
    "        # if resizing was true, we don't need to pad, everything is of the same shape\n",
    "        padded = data\n",
    "    \n",
    "    '''\n",
    "    for p in padded:\n",
    "        r = p.unsqueeze(0)\n",
    "        r = F.interpolate(r, size=dims_resize, mode='bilinear', align_corners = False)\n",
    "        r = r.squeeze(0)\n",
    "        resized.append(r)\n",
    "    '''\n",
    "    \n",
    "    # stack properly now that everything is padded\n",
    "    padded = torch.stack(padded, dim=0)\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    return padded, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = [0]\n",
    "#std = [1]\n",
    "\n",
    "# deal with this later\n",
    "#\n",
    "# we should also probably compute the mean and std manually instead of assuming they correctly\n",
    "# normalized it, since this is the re-recorded dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Normalize(mean, std)\n",
    "  ])\n",
    "test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "#model =  EfficientNetSpectrogram(\"b0\")\n",
    "model = ResNet50Spectrogram()\n",
    "#model = LSTMSpectrogram()\n",
    "model = model.to(device)\n",
    "\n",
    "#epochs = 100\n",
    "epochs = 30\n",
    "batch_size = 32\n",
    "weight_decay = 5e-4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "\n",
    "####################################################\n",
    "# <CHANGE ME> if you want to use different features!\n",
    "####################################################\n",
    "feature_type = \"cqt\"\n",
    "\n",
    "####################################################\n",
    "# <CHANGE ME> if you want to use resizing!\n",
    "#\n",
    "# We need to resize to, for example, (224, 224)\n",
    "####################################################\n",
    "resizing = True\n",
    "dims_resize = (224, 224)\n",
    "\n",
    "FoR_train_loader = None\n",
    "FoR_val_loader = None\n",
    "FoR_test_loader = None\n",
    "\n",
    "# data loaders\n",
    "FoR_train_dataset = SpecDataset(feature_type, \"train\")\n",
    "FoR_val_dataset = SpecDataset(feature_type, \"validation\")\n",
    "FoR_test_dataset = SpecDataset(feature_type, \"test\")\n",
    "\n",
    "FoR_train_loader = DataLoader(FoR_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "FoR_val_loader = DataLoader(FoR_val_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)\n",
    "FoR_test_loader = DataLoader(FoR_test_dataset, batch_size=batch_size, shuffle=True, collate_fn=dynamic_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to compute the equal error rate as one of our metrics.\n",
    "def compute_EER(model, loader):\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            waveform, labels = data\n",
    "            \n",
    "            waveform = waveform.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            out = model(waveform)\n",
    "            out = torch.softmax(out, dim=1)\n",
    "            \n",
    "            # take the positive class labels\n",
    "            out = out[:,1]\n",
    "            \n",
    "            all_scores.extend(out.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # use sklearn to compute this for us\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "    \n",
    "    # definition\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # find closest threshold\n",
    "    eer_thresh = np.nanargmin(np.abs(fpr-fnr))\n",
    "    EER = (fpr[eer_thresh] + fnr[eer_thresh])/2\n",
    "    \n",
    "    return EER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    \n",
    "    for data in loader:\n",
    "        waveform, labels = data\n",
    "        waveform = waveform.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # basic pytorch boilerplate\n",
    "        out = model(waveform)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "    training_loss = training_loss / len(loader)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(loader):\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    \n",
    "    n_correct = 0\n",
    "    n_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            waveform, labels = data\n",
    "            \n",
    "            waveform = waveform.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            out = model(waveform)\n",
    "            loss = criterion(out, labels)\n",
    "            \n",
    "            validation_loss += loss.item()\n",
    "            \n",
    "            # count correct predictions\n",
    "            preds = out.argmax(dim=1)\n",
    "            \n",
    "            n_correct = n_correct + (preds == labels).sum().item()\n",
    "            n_total = n_total + labels.size(0)\n",
    "            \n",
    "    validation_loss = validation_loss / len(loader)\n",
    "    accuracy = n_correct / n_total\n",
    "    \n",
    "    return validation_loss, accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference paper uses patience = 5\n",
    "patience = 5\n",
    "best_validation_loss = 10000.0\n",
    "fail_count = 0\n",
    "\n",
    "training_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    training_loss = train(FoR_train_loader)\n",
    "    print(f\"[Epoch {epoch}] Training Loss: {training_loss}\")\n",
    "    \n",
    "    training_losses.append(training_loss)\n",
    "    \n",
    "    validation_loss, val_accuracy = validate(FoR_val_loader)    \n",
    "    print(f\"[Epoch {epoch}] Validation Loss: {validation_loss} Accuracy: {val_accuracy}\")\n",
    "    \n",
    "    val_losses.append(validation_loss)\n",
    "    \n",
    "    test_loss, test_accuracy = validate(FoR_test_loader)\n",
    "    print(f\"[DEBUG Epoch {epoch}] Test Loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "    \n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    if validation_loss < best_validation_loss:\n",
    "        best_validation_loss = validation_loss\n",
    "        fail_count = 0\n",
    "    else:\n",
    "        # increment number of epochs of no improvement\n",
    "        fail_count = fail_count + 1\n",
    "        \n",
    "    if fail_count >= patience:\n",
    "        print(f\"Triggering early breaking on epoch {epoch}\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test EER: {compute_EER(model, FoR_test_loader)}\")\n",
    "test_loss, test_accuracy = validate(FoR_test_loader)\n",
    "print(f\"Testing loss: {test_loss} Accuracy: {test_accuracy}\")\n",
    "\n",
    "# expected to be quite low, though obvious overfitting at current settings\n",
    "print(f\"Train EER: {compute_EER(model, FoR_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(training_losses)), training_losses, label=\"Training Loss\", marker='o')\n",
    "plt.plot(range(len(val_losses)), val_losses, label=\"Validation Loss\", marker='s')\n",
    "plt.plot(range(len(test_losses)), test_losses, label=\"Test Loss\", marker='x')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs epochs')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj420",
   "language": "python",
   "name": "proj420"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
